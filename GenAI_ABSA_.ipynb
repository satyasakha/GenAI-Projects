{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# **Project : A Case Study of InnovaTech Solutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Business Overview:**\n",
    "\n",
    "InnovaTech Solutions, a dynamic and forward-thinking technology company, has made significant strides in the computing industry with a focus on developing high-quality laptops. Established over a decade ago, InnovaTech has gained a reputation for its innovative approach and commitment to customer satisfaction, creating a significant footprint in both physical and online retail spaces.\n",
    "InnovaTech has expanded its presence in the digital retail world, especially on e-commerce giants like Amazon. This strategic move has not only widened its customer base but also resulted in a large influx of customer feedback, primarily in the form of online reviews. The company's products, notably its range of laptops, have become popular choices on these platforms, leading to an abundance of valuable but underutilized customer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Current Challenge:**\n",
    "\n",
    "InnovaTech currently analyzes customer reviews using basic sentiment analysis tools, which only provide a superficial understanding of customer opinions. In the competitive landscape of the laptop market, a more detailed and aspect-oriented analysis is crucial. Understanding specific customer sentiments on different aspects of laptops, such as user screen, technical specifications, etc, which is vital for targeted product improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Objective:**\n",
    "\n",
    "The primary goal is to conduct a comprehensive aspect-based sentiment analysis of customer reviews for InnovaTech’s laptops, specifically focusing on three critical aspects: the laptop screen, keyboard, and mousepad. These components have been identified as crucial determinants of customer satisfaction and product usability. Project aims to provide nuanced insights into specific areas of customer satisfaction, dissatisfaction, and neutral feedback.The ultimate goal is to enhance overall product quality and customer experience, solidifying InnovaTech's position as a leader in the laptop market.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**Data Description:**\n",
    "\n",
    "The dataset titled \"laptop_reviews.csv\" is structured to facilitate aspect-based sentiment analysis for laptop reviews. Here's a brief description of the data columns:\n",
    "\n",
    "1. id: This column contains unique identifiers for each review entry. It helps in distinguishing and referencing individual reviews\n",
    "2. text: This column includes the actual text of the laptop reviews. The reviews are likely composed of customer opinions and experiences regarding different aspects of the laptops.\n",
    "3. aspects:Contains structured information about specific aspects mentioned in each review like 'RAM', 'screen', 'keyboard', 'mousepad', and others relevant to laptop features.\n",
    "4. category:Provide an additional layer of classification (positive, negative and neutral) for the mentioned aspects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.1 Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28.0 tiktoken datasets session-info --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.2 Imports\n",
    "\n",
    "1. Import all Python packages required to access the Azure Open AI API.\n",
    "2. Import additional packages required to access datasets and create examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import tiktoken\n",
    "import session_info\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.3 Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as az_creds: # Read data from file\n",
    "    data = az_creds.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "creds = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "openai.api_key = creds[\"AZURE_OPENAI_KEY\"]\n",
    "openai.api_base = creds[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "openai.api_type = creds[\"AZURE_OPENAI_APITYPE\"]\n",
    "openai.api_version = creds[\"AZURE_OPENAI_APIVERSION\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "chat_model_id = creds[\"CHATGPT_MODEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1.4 Utilities\n",
    "\n",
    "Define token counter to keep track of the completion window available in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Returns the number of tokens used by a list of messages.\n",
    "    \n",
    "    Args:\n",
    "        messages\n",
    "    \n",
    "    Output:\n",
    "        num_tokens (int): No.of tokens in the message\n",
    "    \n",
    "    Adapted from the OpenAI cookbook token counter.\n",
    "    \n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    \n",
    "    # Each message is sandwiched with <|start|>system or user or assistant {message} and <|end|>  \n",
    "    \n",
    "    tokens_per_message = 3 \n",
    "    \n",
    "    num_tokens = 0\n",
    "    \n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            \n",
    "    num_tokens += 3 # Every reply is primed with <|start|>assistant<|end|>\n",
    "    \n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Task: Aspect-Based Sentiment Analysis (ABSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Step 1: Define objectives & Metrics\n",
    "\n",
    "To evaluate model performance, we judge the accuracy of the aspects + sentiment assignnment per aspect.For example, if aspects identified by the LLM do not match the ground truth for a specific input, we count this prediction to be incorrect. A correct prediction is one where all the aspects are correctly idenfied and further the sentiment assignment for each aspect is also correctly identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_text(input_string):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return formatted string using regular expression\n",
    "    \n",
    "    Args:\n",
    "        input_string (str) : Prediction/Ground Truth strings\n",
    "        \n",
    "    Output:\n",
    "        formatted_string (str) : Formatted string\n",
    "    \"\"\"\n",
    "    \n",
    "    # array\\( for matchin array(\n",
    "    # [^\\[\\]]* matches anything except [] for 0 or more occurences\n",
    "    # \\[[^\\[\\]]*\\] matches [] and everything inside them\n",
    "    # ,dtype=object\\) is for capturing ,dtype=object\\)\n",
    "    # r'\\1' this is the replacement string and '\\1' referes to the first captured group in the regular expression pattern\n",
    " \n",
    "    pattern = r'array\\((\\[[^\\[\\]]*\\]),dtype=object\\)'   \n",
    "    # Replace the array portion with the desired format\n",
    "    formatted_string = re.sub(pattern, r'\\1', input_string) # re.sub is for substitution or replacement\n",
    "    formatted_string = formatted_string.strip()\n",
    "    # print(formatted_string)\n",
    "    \n",
    "    return formatted_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(gold_examples, model_predictions, ground_truths):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the accuracy score comparing the model predictions and ground truth\n",
    "    for ABSA. We look for exact matches between the model predictions on all the\n",
    "    aspects and sentiments for these aspects in the ground truth.\n",
    "\n",
    "    Args:\n",
    "        gold_examples (str): JSON string with list of gold examples\n",
    "        model_predictions (List): Nested list of ABSA predictions\n",
    "        ground_truths (List): Nested list of ABSA annotations\n",
    "\n",
    "    Output:\n",
    "        accuracy (float): Exact matches of model predictions and ground truths\n",
    "    \"\"\"   \n",
    "    \n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(gold_examples)\n",
    "    \n",
    "    for pred, truth in zip(model_predictions, ground_truths):\n",
    "        pred_dict = parse_text(pred)\n",
    "        truth_dict = parse_text(truth)\n",
    "        pred_dict = pred_dict.replace(\" \",\"\")\n",
    "        if pred_dict == truth_dict:\n",
    "            correct_predictions += 1\n",
    "        \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print(\"correct predictions : \", correct_predictions)\n",
    "    print(\"total predictions : \", total_predictions)\n",
    "    print(\"accuracy : \", accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Step 2: Assemble Data\n",
    "\n",
    "1. Use \"laptop_review.csv\" dataset. \n",
    "2. Identify distribution of aspects in examples.\n",
    "3. Identify distribution of aspects in gold examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "laptop_reviews_df = pd.read_csv(\"laptop_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        100 non-null    int64 \n",
      " 1   text      100 non-null    object\n",
      " 2   aspects   100 non-null    object\n",
      " 3   category  100 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.2+ KB\n"
     ]
    }
   ],
   "source": [
    "laptop_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(laptop_reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_reviews_examples, laptop_reviews_gold_examples = train_test_split(\n",
    "    laptop_reviews_df,\n",
    "    test_size=0.2,\n",
    "    random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_reviews_examples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspects</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>The camera is standard. The GPU is great. The ...</td>\n",
       "      <td>{'term':array(['camera','GPU','hardware','scre...</td>\n",
       "      <td>{'category':array(['camera','GPU','hardware','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>The software is standard. The GPU is bad.</td>\n",
       "      <td>{'term':array(['software','GPU'],dtype=object)...</td>\n",
       "      <td>{'category':array(['software','GPU'],dtype=obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>The camera is fair. The design is decent. The ...</td>\n",
       "      <td>{'term':array(['camera','design','RAM','keyboa...</td>\n",
       "      <td>{'category':array(['camera','design','RAM','ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The hardware is average. The mousepad is excel...</td>\n",
       "      <td>{'term':array(['hardware','mousepad'],dtype=ob...</td>\n",
       "      <td>{'category':array(['hardware','mousepad'],dtyp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>The GPU is poor. The camera is bad. The softwa...</td>\n",
       "      <td>{'term':array(['GPU','camera','software','keyb...</td>\n",
       "      <td>{'category':array(['GPU','camera','software','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>55</td>\n",
       "      <td>The battery is excellent. The hardware is disa...</td>\n",
       "      <td>{'term':array(['battery','hardware'],dtype=obj...</td>\n",
       "      <td>{'category':array(['battery','hardware'],dtype...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>The mousepad is decent. The battery is average...</td>\n",
       "      <td>{'term':array(['mousepad','battery','camera','...</td>\n",
       "      <td>{'category':array(['mousepad','battery','camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>The mousepad is excellent. The RAM is fair. Th...</td>\n",
       "      <td>{'term':array(['mousepad','RAM','screen','keyb...</td>\n",
       "      <td>{'category':array(['mousepad','RAM','screen','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>60</td>\n",
       "      <td>The RAM is average. The keyboard is poor. The ...</td>\n",
       "      <td>{'term':array(['RAM','keyboard','software'],dt...</td>\n",
       "      <td>{'category':array(['RAM','keyboard','software'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>The screen is adequate. The hardware is terrib...</td>\n",
       "      <td>{'term':array(['screen','hardware','mousepad',...</td>\n",
       "      <td>{'category':array(['screen','hardware','mousep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  \\\n",
       "69  70  The camera is standard. The GPU is great. The ...   \n",
       "25  26          The software is standard. The GPU is bad.   \n",
       "36  37  The camera is fair. The design is decent. The ...   \n",
       "8    9  The hardware is average. The mousepad is excel...   \n",
       "17  18  The GPU is poor. The camera is bad. The softwa...   \n",
       "54  55  The battery is excellent. The hardware is disa...   \n",
       "21  22  The mousepad is decent. The battery is average...   \n",
       "74  75  The mousepad is excellent. The RAM is fair. Th...   \n",
       "59  60  The RAM is average. The keyboard is poor. The ...   \n",
       "26  27  The screen is adequate. The hardware is terrib...   \n",
       "\n",
       "                                              aspects  \\\n",
       "69  {'term':array(['camera','GPU','hardware','scre...   \n",
       "25  {'term':array(['software','GPU'],dtype=object)...   \n",
       "36  {'term':array(['camera','design','RAM','keyboa...   \n",
       "8   {'term':array(['hardware','mousepad'],dtype=ob...   \n",
       "17  {'term':array(['GPU','camera','software','keyb...   \n",
       "54  {'term':array(['battery','hardware'],dtype=obj...   \n",
       "21  {'term':array(['mousepad','battery','camera','...   \n",
       "74  {'term':array(['mousepad','RAM','screen','keyb...   \n",
       "59  {'term':array(['RAM','keyboard','software'],dt...   \n",
       "26  {'term':array(['screen','hardware','mousepad',...   \n",
       "\n",
       "                                             category  \n",
       "69  {'category':array(['camera','GPU','hardware','...  \n",
       "25  {'category':array(['software','GPU'],dtype=obj...  \n",
       "36  {'category':array(['camera','design','RAM','ke...  \n",
       "8   {'category':array(['hardware','mousepad'],dtyp...  \n",
       "17  {'category':array(['GPU','camera','software','...  \n",
       "54  {'category':array(['battery','hardware'],dtype...  \n",
       "21  {'category':array(['mousepad','battery','camer...  \n",
       "74  {'category':array(['mousepad','RAM','screen','...  \n",
       "59  {'category':array(['RAM','keyboard','software'...  \n",
       "26  {'category':array(['screen','hardware','mousep...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_reviews_examples.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspects</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>The mousepad is unpleasant. The screen is bad.</td>\n",
       "      <td>{'term':array(['mousepad','screen'],dtype=obje...</td>\n",
       "      <td>{'category':array(['mousepad','screen'],dtype=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>The RAM is decent. The hardware is amazing.</td>\n",
       "      <td>{'term':array(['RAM','hardware'],dtype=object)...</td>\n",
       "      <td>{'category':array(['RAM','hardware'],dtype=obj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>The RAM is fair. The GPU is good. The screen i...</td>\n",
       "      <td>{'term':array(['RAM','GPU','screen'],dtype=obj...</td>\n",
       "      <td>{'category':array(['RAM','GPU','screen'],dtype...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>The camera is amazing. The RAM is fair. The ba...</td>\n",
       "      <td>{'term':array(['camera','RAM','battery','mouse...</td>\n",
       "      <td>{'category':array(['camera','RAM','battery','m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>The battery is standard. The mousepad is decen...</td>\n",
       "      <td>{'term':array(['battery','mousepad','hardware'...</td>\n",
       "      <td>{'category':array(['battery','mousepad','hardw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>The design is great. The software is decent. T...</td>\n",
       "      <td>{'term':array(['design','software','GPU'],dtyp...</td>\n",
       "      <td>{'category':array(['design','software','GPU'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>The battery is average. The mousepad is disapp...</td>\n",
       "      <td>{'term':array(['battery','mousepad'],dtype=obj...</td>\n",
       "      <td>{'category':array(['battery','mousepad'],dtype...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The GPU is terrible. The keyboard is poor. The...</td>\n",
       "      <td>{'term':array(['GPU','keyboard','mousepad'],dt...</td>\n",
       "      <td>{'category':array(['GPU','keyboard','mousepad'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>The screen is excellent. The GPU is standard. ...</td>\n",
       "      <td>{'term':array(['screen','GPU','hardware','soft...</td>\n",
       "      <td>{'category':array(['screen','GPU','hardware','...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>The GPU is excellent. The hardware is fair. Th...</td>\n",
       "      <td>{'term':array(['GPU','hardware','RAM','softwar...</td>\n",
       "      <td>{'category':array(['GPU','hardware','RAM','sof...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               text  \\\n",
       "76  77     The mousepad is unpleasant. The screen is bad.   \n",
       "30  31        The RAM is decent. The hardware is amazing.   \n",
       "44  45  The RAM is fair. The GPU is good. The screen i...   \n",
       "80  81  The camera is amazing. The RAM is fair. The ba...   \n",
       "39  40  The battery is standard. The mousepad is decen...   \n",
       "22  23  The design is great. The software is decent. T...   \n",
       "77  78  The battery is average. The mousepad is disapp...   \n",
       "4    5  The GPU is terrible. The keyboard is poor. The...   \n",
       "31  32  The screen is excellent. The GPU is standard. ...   \n",
       "83  84  The GPU is excellent. The hardware is fair. Th...   \n",
       "\n",
       "                                              aspects  \\\n",
       "76  {'term':array(['mousepad','screen'],dtype=obje...   \n",
       "30  {'term':array(['RAM','hardware'],dtype=object)...   \n",
       "44  {'term':array(['RAM','GPU','screen'],dtype=obj...   \n",
       "80  {'term':array(['camera','RAM','battery','mouse...   \n",
       "39  {'term':array(['battery','mousepad','hardware'...   \n",
       "22  {'term':array(['design','software','GPU'],dtyp...   \n",
       "77  {'term':array(['battery','mousepad'],dtype=obj...   \n",
       "4   {'term':array(['GPU','keyboard','mousepad'],dt...   \n",
       "31  {'term':array(['screen','GPU','hardware','soft...   \n",
       "83  {'term':array(['GPU','hardware','RAM','softwar...   \n",
       "\n",
       "                                             category  \n",
       "76  {'category':array(['mousepad','screen'],dtype=...  \n",
       "30  {'category':array(['RAM','hardware'],dtype=obj...  \n",
       "44  {'category':array(['RAM','GPU','screen'],dtype...  \n",
       "80  {'category':array(['camera','RAM','battery','m...  \n",
       "39  {'category':array(['battery','mousepad','hardw...  \n",
       "22  {'category':array(['design','software','GPU'],...  \n",
       "77  {'category':array(['battery','mousepad'],dtype...  \n",
       "4   {'category':array(['GPU','keyboard','mousepad'...  \n",
       "31  {'category':array(['screen','GPU','hardware','...  \n",
       "83  {'category':array(['GPU','hardware','RAM','sof...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_reviews_gold_examples.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'category':array(['battery','RAM','software','GPU'],dtype=object),'polarity':array(['neutral','neutral','neutral','neutral'],dtype=object)}\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_reviews_examples.iloc[0]['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_aspect_index = {\n",
    "    'screen' : [],\n",
    "    'keyboard' : [],\n",
    "    'mousepad' : []\n",
    "}\n",
    "\n",
    "gold_examples_aspect_index = {\n",
    "    'screen' : [],\n",
    "    'keyboard' : [],\n",
    "    'mousepad' : []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, category in zip(laptop_reviews_examples.id, laptop_reviews_examples.category):\n",
    "    for key in examples_aspect_index.keys():\n",
    "        if key in category:\n",
    "            examples_aspect_index[key].append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, category in zip(laptop_reviews_gold_examples.id, laptop_reviews_gold_examples.category):\n",
    "    for key in examples_aspect_index.keys():\n",
    "        if key in category:\n",
    "            gold_examples_aspect_index[key].append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'screen': [54, 45, 91, 77, 32],\n",
       " 'keyboard': [71, 46, 5],\n",
       " 'mousepad': [40, 81, 11, 19, 74, 91, 5, 77, 78, 13]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_examples_aspect_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['id', 'text', 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_examples = json.loads((\n",
    "    laptop_reviews_gold_examples.loc[:, columns_to_select]\n",
    "                                .sample(20, random_state=42)\n",
    "                                .to_json(orient='records')\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 84,\n",
       " 'text': 'The GPU is excellent. The hardware is fair. The RAM is adequate. The software is bad.',\n",
       " 'category': \"{'category':array(['GPU','hardware','RAM','software'],dtype=object),'polarity':array(['positive','neutral','neutral','negative'],dtype=object)}\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Step 3: Derive Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Create prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_template = \"\"\"```{laptop_review}```\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**1. Zero-shot prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "zero_shot_system_message = \"\"\"\n",
    "Perform aspect based sentiment analysis on laptop reviews presented in the input delimited by triple backticks, that is, ```.\n",
    "In each review there might be one or more of the following aspects: screen, keyboard, mousepad.\n",
    "For each review presented as input:\n",
    "- Identify if there are any of the 3 aspects (screen, keyboard, mousepad) present in the review.\n",
    "- Assign a sentiment polarity (positive, negative or neutral) for each aspect\n",
    "\n",
    "Arrange your response a JSON object with the following headers:\n",
    "- category:[list of aspects]\n",
    "- polarity:[list of corresponding polarities for each aspect]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_prompt = [{'role':'system', 'content': zero_shot_system_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**2.Few-shot prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "few_shot_system_message = \"\"\"\n",
    "Perform aspect based sentiment analysis on laptop reviews presented in the input delimited by triple backticks, that is, ```.\n",
    "In each review there might be one or more of the following aspects: screen, keyboard, mousepad.\n",
    "For each review presented as input:\n",
    "- Identify if there are any of the 3 aspects (screen, keyboard, mousepad) present in the review.\n",
    "- Assign a sentiment polarity (positive, negative or neutral) for each aspect\n",
    "\n",
    "Arrange your response a JSON object with the following headers:\n",
    "{category:[list of aspects]\n",
    "polarity:[list of corresponding polarities for each aspect]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(dataset, n=4):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return a JSON list of randomized examples.\n",
    "    Create subsets of each class, choose random samples from the subsets,\n",
    "    merge and randomize the order of samples in the merged list.\n",
    "    Each run of this function creates a different random sample of examples\n",
    "    chosen from the training data.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): A DataFrame with examples\n",
    "        n (int): number of examples of each class to be selected\n",
    "\n",
    "    Output:\n",
    "        randomized_examples (JSON): A JSON with examples in random order\n",
    "    \"\"\"\n",
    "    \n",
    "    columns_to_select = ['id', 'text', 'category']\n",
    "    example_ids = []\n",
    "\n",
    "    aspect_index = {\n",
    "        'keyboard' : [], 'screen' : [], 'mousepad' : []\n",
    "    }\n",
    "\n",
    "    for id, category in zip(dataset.id, dataset.category):\n",
    "        for key in aspect_index.keys():\n",
    "            if key in category:\n",
    "                aspect_index[key].append(id)\n",
    "\n",
    "    for key in aspect_index:\n",
    "        example_ids.extend(np.random.choice(aspect_index[key], n).tolist())\n",
    "\n",
    "    examples = dataset.loc[dataset.id.isin(example_ids), columns_to_select]\n",
    "\n",
    "    return examples.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(system_message, examples, user_message_template):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return a prompt message in the format expected by the Open AI API.\n",
    "    Loop through the examples and parse them as user message and assistant\n",
    "    message.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): system message with instructions for sentiment analysis\n",
    "        examples (str): JSON string with list of examples\n",
    "        user_message_template (str): string with a placeholder for movie reviews\n",
    "\n",
    "    Output:\n",
    "        few_shot_prompt (List): A list of dictionaries in the Open AI prompt format\n",
    "    \"\"\"\n",
    "    \n",
    "    few_shot_prompt = [{'role' : 'system', 'content' : system_message}]\n",
    "\n",
    "    for example in json.loads(examples):\n",
    "        example_input = example['text']\n",
    "        example_absa = example['category']\n",
    "\n",
    "        few_shot_prompt.append(\n",
    "            {\n",
    "                'role' : 'user',\n",
    "                'content' : user_message_template.format(\n",
    "                    laptop_review=example_input\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        few_shot_prompt.append(\n",
    "            {'role' : 'assistant', 'content' : f\"{example_absa}\"}\n",
    "        )\n",
    "\n",
    "    return few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = create_examples(laptop_reviews_df)\n",
    "few_shot_prompt = create_prompt(few_shot_system_message, examples, user_message_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"id\":9,\"text\":\"The hardware is average. The mousepad is excellent.\",\"category\":\"{'category':array(['hardware','mousepad'],dtype=object),'polarity':array(['neutral','positive'],dtype=object)}\"},{\"id\":27,\"text\":\"The screen is adequate. The hardware is terrible. The mousepad is disappointing. The battery is unpleasant.\",\"category\":\"{'category':array(['screen','hardware','mousepad','battery'],dtype=object),'polarity':array(['neutral','negative','negative','negative'],dtype=object)}\"},{\"id\":28,\"text\":\"The screen is adequate. The GPU is disappointing. The hardware is disappointing. The keyboard is excellent.\",\"category\":\"{'category':array(['screen','GPU','hardware','keyboard'],dtype=object),'polarity':array(['neutral','negative','negative','positive'],dtype=object)}\"},{\"id\":36,\"text\":\"The GPU is great. The mousepad is poor. The screen is good.\",\"category\":\"{'category':array(['GPU','mousepad','screen'],dtype=object),'polarity':array(['positive','negative','positive'],dtype=object)}\"},{\"id\":40,\"text\":\"The battery is standard. The mousepad is decent. The hardware is average.\",\"category\":\"{'category':array(['battery','mousepad','hardware'],dtype=object),'polarity':array(['neutral','neutral','neutral'],dtype=object)}\"},{\"id\":44,\"text\":\"The battery is amazing. The screen is standard. The RAM is terrible. The mousepad is standard.\",\"category\":\"{'category':array(['battery','screen','RAM','mousepad'],dtype=object),'polarity':array(['positive','neutral','negative','neutral'],dtype=object)}\"},{\"id\":52,\"text\":\"The mousepad is standard. The keyboard is average. The battery is impressive. The design is disappointing.\",\"category\":\"{'category':array(['mousepad','keyboard','battery','design'],dtype=object),'polarity':array(['neutral','neutral','positive','negative'],dtype=object)}\"},{\"id\":73,\"text\":\"The screen is amazing. The RAM is excellent. The design is terrible.\",\"category\":\"{'category':array(['screen','RAM','design'],dtype=object),'polarity':array(['positive','positive','negative'],dtype=object)}\"},{\"id\":86,\"text\":\"The RAM is amazing. The keyboard is great. The hardware is adequate. The screen is amazing.\",\"category\":\"{'category':array(['RAM','keyboard','hardware','screen'],dtype=object),'polarity':array(['positive','positive','neutral','positive'],dtype=object)}\"},{\"id\":97,\"text\":\"The screen is impressive. The keyboard is standard.\",\"category\":\"{'category':array(['screen','keyboard'],dtype=object),'polarity':array(['positive','neutral'],dtype=object)}\"}]\n"
     ]
    }
   ],
   "source": [
    "print(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "#### Evaluate prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**1. Define Evaluation scorer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt(prompt, gold_examples, user_message_template):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the accuracy score for predictions on gold examples.\n",
    "    For each example, we make a prediction using the prompt. Gold labels and\n",
    "    model predictions are aggregated into lists and compared to compute the\n",
    "    accuracy.\n",
    "\n",
    "    Args:\n",
    "        prompt (List): list of messages in the Open AI prompt format\n",
    "        gold_examples (str): JSON string with list of gold examples\n",
    "        user_message_template (str): string with a placeholder for movie reviews\n",
    "\n",
    "    Output:\n",
    "        accuracy (float): accuracy score computed by comparing model predictions\n",
    "                                with ground truth\n",
    "    \"\"\"\n",
    "    \n",
    "    model_predictions, ground_truths = [], []\n",
    "    \n",
    "\n",
    "    for example in gold_examples:\n",
    "        user_input = [{\n",
    "            'role': 'user',\n",
    "            'content': user_message_template.format(laptop_review=example['text'])\n",
    "        }]\n",
    "\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                deployment_id=chat_model_id,\n",
    "                messages=prompt + user_input,\n",
    "                temperature=0\n",
    "            )\n",
    "            prediction = response['choices'][0]['message']['content']\n",
    "            prediction_dict_str = str(prediction).replace(\"'\", \"\\\"\")\n",
    "            model_predictions.append(prediction_dict_str.strip().lower())\n",
    "            ground_truth_str = str(example['category']).replace(\"'\", \"\\\"\")\n",
    "            ground_truths.append(ground_truth_str.strip().lower())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during model prediction: {e}\")\n",
    "\n",
    "    accuracy = compute_accuracy(gold_examples, model_predictions, ground_truths)\n",
    "    # print(\"accuracy in evaluate_prompt: \", accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**2. Evaluate zero shot prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  3\n",
      "total predictions :  20\n",
      "accuracy :  0.15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_prompt(zero_shot_prompt, gold_examples, user_message_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**3. Evaluate few shot prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_prompt(few_shot_prompt, gold_examples, user_message_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**4. In summary, compute the average (mean) and measure the variability (standard deviation) of the evaluation scores.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "num_eval_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "few_shot_performance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:08<01:18,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:17<01:10,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:26<01:03,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:35<00:53,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  18\n",
      "total predictions :  20\n",
      "accuracy :  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:44<00:43,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:53<00:35,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:02<00:27,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:11<00:17,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:20<00:08,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:28<00:00,  8.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions :  20\n",
      "total predictions :  20\n",
      "accuracy :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(num_eval_runs)):\n",
    "\n",
    "    # For each run create a new sample of examples\n",
    "    examples = create_examples(laptop_reviews_df)\n",
    "\n",
    "    # Assemble the few shot prompt with these examples\n",
    "    few_shot_prompt = create_prompt(few_shot_system_message, examples, user_message_template)\n",
    "\n",
    "    # Evaluate prompt accuracy on gold examples\n",
    "    few_shot_accuracy = evaluate_prompt(few_shot_prompt, gold_examples, user_message_template)\n",
    "\n",
    "    few_shot_performance.append(few_shot_accuracy)\n",
    "    # print(\"few_shot_accuracy : \", few_shot_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 0.029999999999999992)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(few_shot_performance).mean(), np.array(few_shot_performance).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "**----------------------------------------------------------------------------End-----------------------------------------------------------------------------------------**"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
